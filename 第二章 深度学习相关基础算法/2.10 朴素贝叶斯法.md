---
title: 朴素贝叶斯法
categories:      
    Deep Learning    
tags: [Bayes,Deep Learning,Algorithm]
date: 2019-1-6 22:55:03
---

## 摘要

朴素贝叶斯方法是基于贝叶斯定理与条件假设的分类方法

- [1] 特征条件独立假设，求输入/出的联合概率分布d
- [2] 利用贝叶斯定理求出最大后验概率

- [x] Edit By Porter, 积水成渊,蛟龙生焉。

<!-- more -->

## 贝叶斯公式

$$p(c|x)= \frac{p(x|c)P(c)}{P(x)}$$

## 朴素贝叶斯基本方法(X,Y 独立同分布)

训练数据集T:

$$T={(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{N},y_{N}),} $$

由$$P(x,y)$$独立同分布产生.

$$P(Y=c_{k}|X=x)=\frac{P(X=x|Y=c_{k})P(Y=c_{k})}{\sum_{k}^{}P(X=x|Y=c_{k})P(Y=c_{k}) }$$

## 公式概念

- 联合概率分布 

$$P(X,Y)$$ 是独立同分布产生的联合概率分布。

- 先验概率分布 

$$P(Y=c_{k}),k=1,2,3,...,k$$

- 条件概率分布 

$$P(X=x|Y=c_{k}) = P(X^{1}=x^{1},X^{2}=x^{2},...X^{N}=x^{N}|Y=c_{k}) , k=1,2,3,...,k$$

- 后验概率分布

$$P(Y=c_{k}|X=x)$$

## 朴素贝叶斯的表达式

由于朴素二字的前提是独立特征分布概率，所以条件独立假设为(条件概率)为：

$$P(X=x|Y=c_{k})=P(X^{1}=x^{1},X^{2}=x^{2},...,X^{n}=x^{n}|Y=c_{k})$$
$$=\prod _{j=1}^{n}P(X^{j}=x^{j}|Y=c_{k})$$

> 朴素贝叶斯实际上是学习到生成数据的机制，所以属于生成学习模型

## 朴素贝叶斯分类器

于是朴素贝叶斯分类器可表示为:

$$y=f(x)=arg\;max_{c_{k}}\frac{P(Y=c_{k})\prod_{j} P(X^{j}=x^{j}|y=c_{k})}{\sum_{k}^{}P(Y=c_{k})\prod_{j}P(X^{j}=x^{j}|Y=c_{k}) }$$

由于上式分母对$$c_{k}$$，都是相同的，所以分类器的输出y又可以是：

$$y=f(x)=arg\;max_{c_{k}}P(Y=c_{k})\prod_{j} P(X^{j}=x^{j}|y=c_{k})$$

## 贝叶斯估计

### 条件概率贝叶斯估计

$$
P(X^{j}=a_{jl}|Y=c_{k})=\frac{\sum_{i=1}^{N}I(x_{i}^{j}=a_{jl},y_{i}=c_{k})+\lambda }{\sum_{i=1}^{N}I(y_{i}=c_{k})+S_{j}\lambda }, j=1,2,...,n;l=1,2,..,S_{j};k=1,2,...,K
$$

### 先验概率的贝叶斯估计

$$
P(Y=c_{k})=\frac{\sum_{N}^{i=1}I(y_{i}=c_{k})+lambda }{N+k\lambda },k=1,2,...,K
$$

<div>
<iframe height=498 width=100%  src="https://www.bilibili.com/video/av7719936" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>

## 参考

参考文档来源2:[李航-朴素贝叶斯]()
