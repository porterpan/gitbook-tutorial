# 2.1.2 隐马尔科夫HMM

## 一、什么是熵(Entropy)

信息熵的概念这个得从 **热熵** 开始说起，信熵是香农老先生从热力学引进来的，为了表示把信息中排除了冗余后的平均信息量称为“信息熵”。

- 热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。

### 1.1 热力学中--热熵

从能量角度来看,熵定律意味着自然进行的能量转化过程总是由有序度高的能量向有序度低的能量转化,这个过程必定朝着熵增加的方向进行。

高温物体所有分子的平均能量要高于低温物体,所以相接触时总是从高温物体向低温物体传递热量,因为碰撞使它们的状态向平衡过渡,系统才会稳定;

热熵是向着熵增大的方向进行。从宇宙形成到地球诞生以及地球生命的形成,热熵一直有缓慢变大的趋势。

![熵增](./image2/hotShang_1.1.jpeg)

#### 热熵改变是指在某个空间内热量分布的变化。

- 1、在热力学中熵是对热量状态的描述，空间内热量分布差异越大则熵越小，做功的能力越强；空间内热量分布差异越小则熵越大，做功的能力越弱。热熵改变是指在某个空间内热量分布的变化，熵越大则热量分布的差异越小。正常情况下熵会从小到大的变化，最终熵达到最大而呈热寂。

- 2、根据热力学第二定律，作为一个“孤立”的系统，宇宙的熵会随着时间的流逝而增加，由有序向无序，当宇宙的熵达到最大值时，宇宙中的其他有效能量已经全数转化为热能，所有物质温度达到热平衡。这种状态称为热寂。这样的宇宙中再也没有任何可以维持运动或是生命的能量存在。
- 3、热熵改变的本质是热量分布由有序向无序发展，所以也可以看成系统混乱程度的改变。
- 4、熵最初是根据热力学第二定律引出的一个反映自发过程不可逆性的物质状态参量。热力学第二定律是根据大量观察结果总结出来的规律，有下述表述方式：热量总是从高温物体传到低温物体，不可能作相反的传递而不引起其他的变化；功可以全部转化为热，但任何热机不能全部地，连续不断地把所接受的热量转变为功；在孤立系统中，实际发生过程总使整个系统的熵值增大，此即熵增原理。 
> 简单总结：热熵是熵增的过程，热量由有序的状态，转移，或是机械能，或是向其他低温物体转移，产生的影响是，最终达到系统平衡的目的，但也使得整个系统不再是以前清晰的状态，相反是变成了另一种混乱的状态，可以这样白话理解。

### 1.2 信息论中的信息熵--信熵

- 香农用信息熵的概念来描述信源的不确定度。

根据Charles H. Bennett对Maxwell's Demon的重新解释，对信息的销毁是一个不可逆过程，所以销毁信息是符合热力学第二定律的。而产生信息，则是为系统引入负（热力学）熵的过程。所以信息熵的符号与热力学熵应该是相反的。

* 假设离散随机变量X的概率分布为P(x)，则其熵为：

![熵增](./image2/hotShang_1.2.jpeg)

H(x) = E[I(xi)] = E[ log(2,1/p(xi)) ] = -∑p(xi)log(2,p(xi)) (i=1,2,..n)

其中，x表示随机变量，与之相对应的是所有可能输出的集合，定义为符号集,随机变量的输出用x表示。P(x)表示输出概率函数。**变量的不确定性越大，熵也就越大** ，把它搞清楚所需要的信息量也就越大.

能量角度，高温向低温转变，一般是熵增的过程；而信息论中，为了最大可能接收到正确的（发出==收到）的信息，我们处理（优化）系统，是一种熵减的过程，信熵越小，系统有用信息量越大。

信息熵：**信息的基本作用就是消除人们对事物的不确定性** 。多数粒子组合之后，在它似像非像的形态上押上有价值的数码，具体地说，这就是一个在博弈对局中现象信息的混乱。

#### 举个例子

-(p1*log(2,p1) + p2 * log(2,p2) +　．．．　+p32 *log(2,p32))，其中，p1，p2 ，　．．．，p32 分别是这 32 个球队夺冠的概率。香农把它称为“信息熵” (Entropy)，一般用符号 H 表示，单位是比特。

![熵增](./image2/hotShang_1.3.jpeg)

有兴趣的读者可以推算一下当 32 个球队夺冠概率相同时，对应的信息熵等于五比特。有数学基础的读者还可以证明上面公式的值不可能大于五。因为得冠军的频率相同代表整个系统信息量最小。


熵是随机变量不确定性的度量，不确定性越大，熵值就越大；若随机变量退化成定值，熵为0。均匀分布(信熵最大)是“最不确定”的分布。

熵最早来原于物理学. 德国物理学家鲁道夫·克劳修斯首次提出熵的概念，用来表示任何一种能量在空间中分布的均匀程度，能量分布得越均匀，熵就越大。

> 总结：香农，描述一个信息系统的时候就借用了熵的概念，这里熵表示的是这个信息系统的平均信息量(平均不确定程度),信熵越小，系统信息不确定程度越低，反之，系统信息输出越混乱，有用信息越不容易被确认。

### 1.3 联合熵

联合熵是一集变量之间不确定性的衡量手段。两个变量和的联合信息熵定义为：

![联合熵](./image2/lianheShang1.3.1.png)

- 一集变量的联合熵大于或等于这集变量中任一个的独立熵。

![联合熵](./image2/lianheShang1.3.2.png) 

- 少于独立熵的和

![联合熵](./image2/lianheShang1.3.3.png) 

这表明，两个变量关联之后不确定性会增大，但是又由于相互有制约关系，不确定小于单独两个变量的不确定度之和。

### 1.4 条件熵

- 条件熵H(X|Y) = H(X,Y) - H(Y)

> X在条件Y下的条件熵

![条件熵](./image2/tiaojianShang1.4.1.png) 

### 15 相对熵与互信息



















## 二、最大熵模型

* 最大熵模型在形式上是最漂亮的统计模型，而在实现上是最复杂的模型之一。最大熵模型，可以说是集简与繁于一体，形式简单，实现复杂。值得一提的是，在Google的很多产品中，比如机器翻译，都直接或间接地用到了最大熵模型。 

* 达拉皮垂兄弟等科学家在那里，用于最大熵模型和其他一些先进的数学工具对股票预测，获得了巨大的成功。(值得一提的是，信息处理的很多数学手段，包括隐含马尔可夫模型、子波变换、贝叶斯网络等等，在华尔街多有直接的应用。由此可见，数学模型的作用)。


## 三、HMM（隐马尔可夫模型）