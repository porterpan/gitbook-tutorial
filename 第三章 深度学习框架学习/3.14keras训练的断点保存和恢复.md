---
title: 3.14keras训练的断点保存和恢复
localimage: image3
urlname: keras_checkpoint_rstore
categories:      
    keras      
tags: [Deep Learning,recognition]
date: 2019-11-14 10:45:03
---

# 摘要

keras 训练大量数据集时，我们不希望因为断点或者别的干扰下，存在训练中断，然后下次又是重头开始训练的这种情况。好在keras和tensorflow一样都是存在训练中的断点保存和恢复功能，本文主要通过代码例程来演示如何使用keras中的断点保存和恢复功能。

- [x] Edit By Porter, 积水成渊,蛟龙生焉。

<!-- more -->

### 第一步：导入ModelCheckpoint模块

导入断点保存和恢复的模块和断点保存的路径。
```python
from keras.callbacks import ModelCheckpoint
# 断点保存的路径
checkpoint_dir = './work/keras_model/checkpoint-best.hdf5'
```

### 第二步：创建模型保存的本地文件夹

```python
# 创建断点复训文件夹
if not os.path.exists('./work/keras_model/'):
    os.mkdir('./work/keras_model/')
```

### 第三步：检测是否存在上次训练保存的模型参数

每次运行程序前，检测本地文件夹里是否存在上次保存的模型训练参数保存的文件夹


```python
if os.path.exists(checkpoint_dir):
    print('INFO:checkpoint exists, Load weights from %s\n'%checkpoint_dir)
    model.load_weights(checkpoint_dir) #　加载断点文件夹
else:
    print('No checkpoint found')
```

### 第四步：创建模型断点保存函数

这个函数作为模型训练中的模型参数保存的文件，我们每次按指定次数，将当前的训练参数保存在本地的文件中。

```python
checkpoint = ModelCheckpoint(checkpoint_dir,
    monitor='val_loss', 
    save_weights_only=True,
    verbose=1,
    save_best_only=True, 
    period=1)
```

### 第五步：通过开始训练的函数调用第四步中的回调函数

```python
#拟合模型
history = model.fit_generator(
    train_generator,
    steps_per_epoch=29620//50,#迭代进入下一轮次需要抽取的批次
    epochs=30,#数据迭代的轮数
    validation_data=val_generator,
    validation_steps=30,#验证集用于评估的批次
    initial_epoch=27, #再训练时的初始回合数，一般断点后，这个值设置你之前断点结束后的值
    callbacks=[checkpoint])# 回调函数，断点的保存
```



