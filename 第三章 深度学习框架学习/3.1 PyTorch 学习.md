---
title: 3.1 PyTorch 学习
categories:      
    Deep Learning      
tags: [Deep Learning,PyTorch]
date: 2018-11-10 22:55:03
---

# 摘要

本节主要是学习PyTorch相关的学习，主要是基础的学习路线，包括简单的实例笔记等。

- [x] Edit By Porter, 积水成渊,蛟龙生焉。

<!-- more -->

帮助文档见[PyTorch官网](https://pytorch.org/tutorials/)

# 一、张量(tensor)和变量(Variable)

PyTorch的官方介绍是一个拥有强力GPU加速的张量和动态构建网络的库，其主要构建是张量，所以可以把PyTorch当做Numpy来用，Pytorch的很多操作好比Numpy都是类似的，但是其能够在GPU上运行，所以有着比Numpy快很多倍的速度。

```Python
import torch
import numpy as np

numpy_tensor = np.random.randn(3, 4)

pytorch_tensor1 = torch.Tensor(numpy_tensor)
pytorch_tensor2 = torch.from_numpy(numpy_tensor)

print(pytorch_tensor1)
print(pytorch_tensor2)
```
输出结果：

```Python
pytorch_tensor1:

tensor([[ 1.3511,  0.2016, -0.9728,  0.7997],
        [-1.0706, -0.0768, -1.3627, -0.8809],
        [-0.6040, -0.0030,  0.4871,  0.6634]])
```

```Python
pytorch_tensor2:

tensor([[ 1.3511,  0.2016, -0.9728,  0.7997],
        [-1.0706, -0.0768, -1.3627, -0.8809],
        [-0.6040, -0.0030,  0.4871,  0.6634]], dtype=torch.float64)
```

使用以上两种方法进行转换的时候，会直接将Numpy ndarray的数据类型转换为对应的Pytorch Tensor数据类型,同时我们也可以使用下面的方法将pytorch tensor转换为numpy ndarray

```Python
import torch
import numpy as np

numpy_tensor = np.random.randn(3, 4)
pytorch_tensor1 = torch.Tensor(numpy_tensor)
pytorch_tensor2 = torch.from_numpy(numpy_tensor)

# 如果pytorch tensor在cpu上
numpy_array1 = pytorch_tensor1.numpy()
numpy_array2 = pytorch_tensor2.cpu().numpy()

print(numpy_array1)
print(numpy_array2)
```

```Python 
numpy_array1:

[[ 0.9646071   1.0680387  -1.4145772  -1.1733457 ]
 [ 0.14683424  0.15183815  0.3256755   2.5129247 ]
 [-1.0027096   0.02551154 -0.60790646 -0.22400694]]

 numpy_array2:

[[-2.09633392 -2.08986247  0.02169762  0.15833546]
 [ 1.24929483 -1.3953018   1.03153148 -0.06309232]
 [ 0.24348084 -1.42512446  1.45863934  0.92882537]]
```

需要注意GPU上的Tensor不能直接转换为Numpy ndarray，需要使用.cpu()先将GPU上的Tensor转到CPU上 PyTorch Tensor 使用GPU加速可以使用下面两种方法将Tensor放到GPU上.

```Python
# 第一种方式是定义cuda数据类型
dtype = torch.cuda.FloatTensor
gpu_tensor = torch.randn(10,20).type(dtype)

# 第二种方式更简单，推荐使用
gpu_tensor = torch.randn(10,20).cuda(0) # 将tensor放到第一个GPU上
gpu_tensor = torch.randn(10,20).cuda(1) # 将tensor放到第二个GPU上
```

* 使用第一种方式将tensor放到GPU上的时候会将数据类型转换成定义的类型。

* 而使用第二种方式能够直接将tensor放到GPU上，类型跟之前保持一致。

> 推荐在定义tensor的时候就明确数据类型，然后直接使用第二种方法将tensor放到GPU上

我的测试代码：

```Python
import torch
import numpy as np

numpy_tensor = np.random.randn(3, 4)
pytorch_tensor1 = torch.Tensor(numpy_tensor)
pytorch_tensor2 = torch.from_numpy(numpy_tensor)

# 如果pytorch tensor在cpu上
numpy_array1 = pytorch_tensor1.numpy()
numpy_array2 = pytorch_tensor2.cpu().numpy()

print(numpy_array1)
print(numpy_array2)

print("输出数据模式1：")
# 第一种方式是定义cuda数据类型
dtype = torch.cuda.FloatTensor
gpu_tensor1 = torch.randn(3,4).type(dtype)

print(gpu_tensor1)

gpu_tensor2 = torch.randn(3,4).cuda(0) # 将tensor放到第一个GPU上

print("输出数据模式2：")
print(gpu_tensor2)
```


