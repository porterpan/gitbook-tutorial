---
title: 3.2 tensorflow1.x常用函数使用
localimage: image3
urlname: Tensorflow_common_function
categories:
    tf
tags: [Deep Learning,tensorflow]
date: 2018-7-14 22:55:03
---


# 摘要

本文记录tensorflow的学习入门过程，主要是tensorflow中的常用函数的介绍。

Tensorflow的设计理念称之为计算流图，在编写程序时，首先构筑整个系统的graph，代码并不会直接生效，这一点和python的其他数值计算库（如Numpy等）不同，graph为静态的，类似于docker中的镜像。

然后，在实际的运行时，启动一个session，程序才会真正的运行。这样做的好处就是：避免反复地切换底层程序实际运行的上下文，tensorflow帮你优化整个系统的代码。我们知道，很多python程序的底层为C语言或者其他语言，执行一行脚本，就要切换一次，是有成本的，tensorflow通过计算流图的方式，帮你优化整个session需要执行的代码，还是很有优势的。

       所以placeholder()函数是在神经网络构建graph的时候在模型中的占位，此时并没有把要输入的数据传入模型，它只会分配必要的内存。等建立session，在会话中，运行模型的时候通过feed_dict()函数向占位符喂入数据。

--------------------- 
作者：清晨的光明 
来源：CSDN 
原文：https://blog.csdn.net/kdongyi/article/details/82343712 
版权声明：本文为博主原创文章，转载请附上博文链接！

<!-- more -->


### tf.Session()

TensorFlow 运行模型 --- 会话

会话拥有并管理TensrFlow程序运行的所有资源。

### tf.placeholder()

```python
tf.placeholder(
    dtype,
    shape=None,
    name=None
)
```

- 参数：

**dtype：** 数据类型。常用的是tf.float32,tf.float64等数值类型

**shape：** 数据形状。默认是None，就是一维值，也可以是多维（比如[2,3], [None, 3]表示列是3，行不定）

**name：** 名称

placeholder()函数是在神经网络构建graph的时候在模型中的占位，此时并没有把要输入的数据传入模型，它只会分配必要的内存。等建立session，在会话中，运行模型的时候通过feed_dict()函数向占位符喂入数据。

- 例子
```python
import tensorflow as tf
import numpy as np
 
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)
 
output = tf.multiply(input1, input2)
 
with tf.Session() as sess:
    print sess.run(output, feed_dict = {input1:[3.], input2: [4.]})
```

### tf.truncated_normal


### tf.greater()

```python
def greater(x: Any,
            y: Any,
            name: Any = None) -> object
```
Returns the truth value of (x > y) element-wise.
NOTE: math.greater supports broadcasting. More

tf.greater(x,y), 即和c语言的条件语句 x>y?True:Flase;但是不用的是，这个函数返回bool值。

### tf.where()

```python
def where(condition: Any,
          x: Any = None,
          y: Any = None,
          name: Any = None) -> Any
```

Return the elements, either from x or y, depending on the condition.

### tf.train.exponential_decay()

tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, LEARNING_RATE_STEP,LEARNING_RATE_DECAY, staircase=True)

